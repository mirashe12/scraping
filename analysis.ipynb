{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "path=\"C:/Users/rohit/scraping/txt_files\"\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "def read_words(file_path):\n",
    "    words = set()\n",
    "    with open(file_path, 'r') as file:\n",
    "        for line in file:\n",
    "            words.add(line.strip())\n",
    "    return words\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "ename": "FileNotFoundError",
     "evalue": "[Errno 2] No such file or directory: 'C:/Users/rohit/OneDrive/Desktop/balckcoffer/MasterDictionary/positive-words.txt'",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mFileNotFoundError\u001b[0m                         Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[6], line 3\u001b[0m\n\u001b[0;32m      1\u001b[0m \u001b[38;5;66;03m# Example usage:\u001b[39;00m\n\u001b[0;32m      2\u001b[0m positive_words_file \u001b[38;5;241m=\u001b[39m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mC:/Users/rohit/OneDrive/Desktop/balckcoffer/MasterDictionary/positive-words.txt\u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[1;32m----> 3\u001b[0m positive_words \u001b[38;5;241m=\u001b[39m \u001b[43mread_words\u001b[49m\u001b[43m(\u001b[49m\u001b[43mpositive_words_file\u001b[49m\u001b[43m)\u001b[49m\n",
      "Cell \u001b[1;32mIn[5], line 3\u001b[0m, in \u001b[0;36mread_words\u001b[1;34m(file_path)\u001b[0m\n\u001b[0;32m      1\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mread_words\u001b[39m(file_path):\n\u001b[0;32m      2\u001b[0m     words \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mset\u001b[39m()\n\u001b[1;32m----> 3\u001b[0m     \u001b[38;5;28;01mwith\u001b[39;00m \u001b[38;5;28;43mopen\u001b[39;49m\u001b[43m(\u001b[49m\u001b[43mfile_path\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[38;5;124;43mr\u001b[39;49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[43m)\u001b[49m \u001b[38;5;28;01mas\u001b[39;00m file:\n\u001b[0;32m      4\u001b[0m         \u001b[38;5;28;01mfor\u001b[39;00m line \u001b[38;5;129;01min\u001b[39;00m file:\n\u001b[0;32m      5\u001b[0m             words\u001b[38;5;241m.\u001b[39madd(line\u001b[38;5;241m.\u001b[39mstrip())\n",
      "File \u001b[1;32mc:\\Users\\rohit\\scraping\\soup\\Lib\\site-packages\\IPython\\core\\interactiveshell.py:310\u001b[0m, in \u001b[0;36m_modified_open\u001b[1;34m(file, *args, **kwargs)\u001b[0m\n\u001b[0;32m    303\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m file \u001b[38;5;129;01min\u001b[39;00m {\u001b[38;5;241m0\u001b[39m, \u001b[38;5;241m1\u001b[39m, \u001b[38;5;241m2\u001b[39m}:\n\u001b[0;32m    304\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mValueError\u001b[39;00m(\n\u001b[0;32m    305\u001b[0m         \u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mIPython won\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mt let you open fd=\u001b[39m\u001b[38;5;132;01m{\u001b[39;00mfile\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m by default \u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[0;32m    306\u001b[0m         \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mas it is likely to crash IPython. If you know what you are doing, \u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[0;32m    307\u001b[0m         \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124myou can use builtins\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124m open.\u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[0;32m    308\u001b[0m     )\n\u001b[1;32m--> 310\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mio_open\u001b[49m\u001b[43m(\u001b[49m\u001b[43mfile\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n",
      "\u001b[1;31mFileNotFoundError\u001b[0m: [Errno 2] No such file or directory: 'C:/Users/rohit/OneDrive/Desktop/balckcoffer/MasterDictionary/positive-words.txt'"
     ]
    }
   ],
   "source": [
    "# Example usage:\n",
    "positive_words_file = \"C:/Users/rohit/OneDrive/Desktop/balckcoffer/MasterDictionary/positive-words.txt\"\n",
    "positive_words = read_words(positive_words_file)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'winnable',\n",
       " 'user-replaceable',\n",
       " 'polite',\n",
       " 'divinely',\n",
       " 'exaltedly',\n",
       " 'prospros',\n",
       " 'inventive',\n",
       " 'blossom',\n",
       " 'foresight',\n",
       " 'eulogize',\n",
       " 'futurestic',\n",
       " 'best-performing',\n",
       " 'improve',\n",
       " 'congratulation',\n",
       " 'genial',\n",
       " 'overtakes',\n",
       " 'exceeded',\n",
       " 'hail',\n",
       " 'magnificently',\n",
       " 'fearlessly',\n",
       " 'cool',\n",
       " 'cute',\n",
       " 'prompt',\n",
       " 'outperformed',\n",
       " 'sufficed',\n",
       " 'zest',\n",
       " 'catchy',\n",
       " 'courageousness',\n",
       " 'plush',\n",
       " 'jubilation',\n",
       " 'expansive',\n",
       " 'patiently',\n",
       " 'conscientious',\n",
       " 'strikingly',\n",
       " 'support',\n",
       " 'reasonably',\n",
       " 'fancier',\n",
       " 'rockstar',\n",
       " 'compassion',\n",
       " 'perfection',\n",
       " 'respectfully',\n",
       " 'wonderful',\n",
       " 'chivalry',\n",
       " 'sumptuously',\n",
       " 'fave',\n",
       " 'logical',\n",
       " 'dawn',\n",
       " 'significant',\n",
       " 'compassionate',\n",
       " 'edify',\n",
       " 'enrichment',\n",
       " 'satisfying',\n",
       " 'doubtless',\n",
       " 'ergonomical',\n",
       " 'qualified',\n",
       " 'leverage',\n",
       " 'worthy',\n",
       " 'affection',\n",
       " 'unaffected',\n",
       " 'smooth',\n",
       " 'bullish',\n",
       " 'accolades',\n",
       " 'assurance',\n",
       " 'well-positioned',\n",
       " 'beloved',\n",
       " 'swift',\n",
       " 'enticed',\n",
       " 'rapport',\n",
       " 'restful',\n",
       " 'stirringly',\n",
       " 'authoritative',\n",
       " 'endorses',\n",
       " 'restored',\n",
       " 'striking',\n",
       " 'stately',\n",
       " 'commitment',\n",
       " 'fun',\n",
       " 'shine',\n",
       " 'promising',\n",
       " 'enticingly',\n",
       " 'illuminate',\n",
       " 'luckiness',\n",
       " 'intriguingly',\n",
       " 'cohere',\n",
       " 'well-known',\n",
       " 'euphorically',\n",
       " 'adequate',\n",
       " 'superiority',\n",
       " 'first-rate',\n",
       " 'fans',\n",
       " 'hallmark',\n",
       " 'loved',\n",
       " 'simplifies',\n",
       " 'exuberance',\n",
       " 'brainy',\n",
       " 'convience',\n",
       " 'affectation',\n",
       " 'outdo',\n",
       " 'positives',\n",
       " 'vigilant',\n",
       " 'diligence',\n",
       " 'elatedly',\n",
       " 'intuitive',\n",
       " 'warm',\n",
       " 'passionately',\n",
       " 'dexterous',\n",
       " 'smoothly',\n",
       " 'unequivocally',\n",
       " 'treasure',\n",
       " 'workable',\n",
       " 'hearten',\n",
       " 'cuteness',\n",
       " 'extraordinary',\n",
       " 'flashy',\n",
       " 'astoundingly',\n",
       " 'gems',\n",
       " 'fair',\n",
       " 'stunning',\n",
       " 'freedom',\n",
       " 'enthusiasm',\n",
       " 'promptly',\n",
       " 'complements',\n",
       " 'vibrantly',\n",
       " 'stimulative',\n",
       " 'prettily',\n",
       " 'empower',\n",
       " 'fame',\n",
       " 'brighten',\n",
       " 'boom',\n",
       " 'gallant',\n",
       " 'accommodative',\n",
       " 'uncomplicated',\n",
       " 'loving',\n",
       " 'god-send',\n",
       " 'god-given',\n",
       " 'pleasurably',\n",
       " 'obtainable',\n",
       " 'refinement',\n",
       " 'free',\n",
       " 'progress',\n",
       " 'suavely',\n",
       " 'lawful',\n",
       " 'windfall',\n",
       " 'progressive',\n",
       " 'unrestricted',\n",
       " 'defeating',\n",
       " 'maturity',\n",
       " 'entice',\n",
       " 'gallantly',\n",
       " 'influential',\n",
       " 'healthful',\n",
       " 'paradise',\n",
       " 'smoother',\n",
       " 'enlighten',\n",
       " 'everlasting',\n",
       " 'convenient',\n",
       " 'prosperity',\n",
       " 'simplest',\n",
       " 'famed',\n",
       " 'champ',\n",
       " 'angel',\n",
       " 'chivalrous',\n",
       " 'salutary',\n",
       " 'enterprising',\n",
       " 'subsidizing',\n",
       " 'gush',\n",
       " 'delighted',\n",
       " 'grace',\n",
       " 'compactly',\n",
       " 'unfettered',\n",
       " 'exaltation',\n",
       " 'jaw-dropping',\n",
       " 'amazed',\n",
       " 'bloom',\n",
       " 'improvements',\n",
       " 'affectionate',\n",
       " 'venerate',\n",
       " 'seamless',\n",
       " 'vouch',\n",
       " 'resolute',\n",
       " 'selective',\n",
       " 'cleaner',\n",
       " 'lower-priced',\n",
       " 'steadfastness',\n",
       " 'refine',\n",
       " 'glowing',\n",
       " 'pinnacle',\n",
       " 'interests',\n",
       " 'simplifying',\n",
       " 'salute',\n",
       " 'liberation',\n",
       " 'geeky',\n",
       " 'frolic',\n",
       " 'rapid',\n",
       " 'perseverance',\n",
       " 'fiery',\n",
       " 'effortless',\n",
       " 'undisputably',\n",
       " 'upscale',\n",
       " 'witty',\n",
       " 'ardor',\n",
       " 'resound',\n",
       " 'advantageous',\n",
       " 'exceptional',\n",
       " 'praiseworthy',\n",
       " 'affluence',\n",
       " 'sweetly',\n",
       " 'low-risk',\n",
       " 'masters',\n",
       " 'shiny',\n",
       " 'beauteous',\n",
       " 'better-than-expected',\n",
       " 'glimmer',\n",
       " 'fervor',\n",
       " 'bless',\n",
       " 'miraculously',\n",
       " 'joyously',\n",
       " 'suitable',\n",
       " 'halcyon',\n",
       " 'swankiest',\n",
       " 'excited',\n",
       " 'well-educated',\n",
       " 'gratify',\n",
       " 'revolutionize',\n",
       " 'affable',\n",
       " 'peacekeepers',\n",
       " 'wonderously',\n",
       " 'secure',\n",
       " 'gleeful',\n",
       " 'neatest',\n",
       " 'jovial',\n",
       " 'properly',\n",
       " 'gutsy',\n",
       " 'enjoyably',\n",
       " 'cherished',\n",
       " 'brilliance',\n",
       " 'apotheosis',\n",
       " 'enviously',\n",
       " 'mercifully',\n",
       " 'defeats',\n",
       " 'patriotic',\n",
       " 'prefers',\n",
       " 'comely',\n",
       " 'miracle',\n",
       " 'resilient',\n",
       " 'luckiest',\n",
       " 'exhilarate',\n",
       " 'wholeheartedly',\n",
       " 'beckoning',\n",
       " 'palatial',\n",
       " 'punctual',\n",
       " 'suave',\n",
       " 'impressed',\n",
       " 'prestige',\n",
       " 'oasis',\n",
       " 'blockbuster',\n",
       " 'joyful',\n",
       " 'exhilarating',\n",
       " 'complimentary',\n",
       " 'entertains',\n",
       " 'expeditiously',\n",
       " 'splendid',\n",
       " 'faster',\n",
       " 'liberty',\n",
       " 'accessible',\n",
       " 'considerate',\n",
       " 'celebrate',\n",
       " 'suffice',\n",
       " 'unabashedly',\n",
       " 'sweetness',\n",
       " 'comfortably',\n",
       " 'liking',\n",
       " 'advantages',\n",
       " 'cushy',\n",
       " 'valiantly',\n",
       " 'nimble',\n",
       " 'ecenomical',\n",
       " 'heartfelt',\n",
       " 'heroically',\n",
       " 'luminous',\n",
       " 'eases',\n",
       " 'plentiful',\n",
       " 'satisified',\n",
       " 'sporty',\n",
       " 'versatile',\n",
       " 'romantically',\n",
       " 'prestigious',\n",
       " 'renewed',\n",
       " 'feat',\n",
       " 'cost-effective',\n",
       " 'gainfully',\n",
       " 'sufficient',\n",
       " 'awesomeness',\n",
       " 'remission',\n",
       " 'extol',\n",
       " 'powerfully',\n",
       " 'excitedness',\n",
       " 'fond',\n",
       " 'spiritual',\n",
       " 'meticulous',\n",
       " 'excitingly',\n",
       " 'neatly',\n",
       " 'well-wishers',\n",
       " 'fidelity',\n",
       " 'rewardingly',\n",
       " 'righteous',\n",
       " 'beautifully',\n",
       " 'amazes',\n",
       " 'faithful',\n",
       " 'deft',\n",
       " 'diplomatic',\n",
       " 'tantalizingly',\n",
       " 'exaltingly',\n",
       " 'jollify',\n",
       " 'durable',\n",
       " 'truthful',\n",
       " 'deserving',\n",
       " 'revives',\n",
       " 'firmer',\n",
       " 'scenic',\n",
       " 'laudably',\n",
       " 'groundbreaking',\n",
       " 'ideally',\n",
       " 'energetic',\n",
       " 'beneficent',\n",
       " 'sparkling',\n",
       " 'fancy',\n",
       " 'preferes',\n",
       " 'self-satisfaction',\n",
       " 'consistent',\n",
       " 'trivially',\n",
       " 'ingenious',\n",
       " 'awestruck',\n",
       " 'pain-free',\n",
       " 'hug',\n",
       " 'pleasantly',\n",
       " 'smitten',\n",
       " 'popular',\n",
       " 'unreal',\n",
       " 'securely',\n",
       " 'flawless',\n",
       " 'magnificent',\n",
       " 'cheer',\n",
       " 'protect',\n",
       " 'attune',\n",
       " 'relief',\n",
       " 'spellbound',\n",
       " 'impressively',\n",
       " 'appreciated',\n",
       " 'marvel',\n",
       " 'merriment',\n",
       " 'eye-catching',\n",
       " 'pride',\n",
       " 'patriot',\n",
       " 'rectify',\n",
       " 'fondness',\n",
       " 'simpler',\n",
       " 'astound',\n",
       " 'monumental',\n",
       " 'revolutionizes',\n",
       " 'freshest',\n",
       " 'harmonize',\n",
       " 'versatility',\n",
       " 'noiseless',\n",
       " 'noble',\n",
       " 'obsession',\n",
       " 'award',\n",
       " 'faultless',\n",
       " 'imaginative',\n",
       " 'protective',\n",
       " 'propitiously',\n",
       " 'rapturous',\n",
       " 'energy-saving',\n",
       " 'trendy',\n",
       " 'ingeniously',\n",
       " 'gratitude',\n",
       " 'contrasty',\n",
       " 'outshone',\n",
       " 'lucidly',\n",
       " 'nourishing',\n",
       " 'positively',\n",
       " 'unmatched',\n",
       " 'permissible',\n",
       " 'self-respect',\n",
       " 'rapture',\n",
       " 'enviable',\n",
       " 'personalized',\n",
       " 'thriving',\n",
       " 'thumbs-up',\n",
       " 'honoring',\n",
       " 'attractive',\n",
       " 'luxurious',\n",
       " 'exceedingly',\n",
       " 'wonderous',\n",
       " 'invulnerable',\n",
       " 'intimacy',\n",
       " 'tranquil',\n",
       " 'fondly',\n",
       " 'sagacity',\n",
       " 'glee',\n",
       " 'colorful',\n",
       " 'like',\n",
       " 'err-free',\n",
       " 'delicious',\n",
       " 'marvelously',\n",
       " 'dead-cheap',\n",
       " 'purposeful',\n",
       " 'first-class',\n",
       " 'attraction',\n",
       " 'diligently',\n",
       " 'stimulating',\n",
       " 'notably',\n",
       " 'merry',\n",
       " 'humility',\n",
       " 'reconciliation',\n",
       " 'undisputed',\n",
       " 'respectable',\n",
       " 'enthusiastic',\n",
       " 'superior',\n",
       " 'veritable',\n",
       " 'nourishment',\n",
       " 'ecstatic',\n",
       " 'calmness',\n",
       " 'problem-free',\n",
       " 'enhanced',\n",
       " 'saint',\n",
       " 'cooperative',\n",
       " 'unquestionably',\n",
       " 'innovation',\n",
       " 'auspicious',\n",
       " 'leads',\n",
       " 'improvement',\n",
       " 'lavishly',\n",
       " 'successfully',\n",
       " 'gloriously',\n",
       " 'lawfully',\n",
       " 'solid',\n",
       " 'meaningful',\n",
       " 'user-friendly',\n",
       " 'well-made',\n",
       " 'playful',\n",
       " 'lifesaver',\n",
       " 'avidly',\n",
       " 'ecstatically',\n",
       " 'stimulates',\n",
       " 'felicity',\n",
       " 'luxury',\n",
       " 'exalt',\n",
       " 'unparalleled',\n",
       " 'bonuses',\n",
       " 'celebrated',\n",
       " 'impartially',\n",
       " 'inspiring',\n",
       " 'faithfully',\n",
       " 'orderly',\n",
       " 'coolest',\n",
       " 'well-backlit',\n",
       " 'impartiality',\n",
       " 'saver',\n",
       " 'reachable',\n",
       " 'clearly',\n",
       " 'gain',\n",
       " 'awe',\n",
       " 'champion',\n",
       " 'luster',\n",
       " 'preferable',\n",
       " 'regal',\n",
       " 'achievible',\n",
       " 'hilarious',\n",
       " 'instructive',\n",
       " 'geekier',\n",
       " 'supple',\n",
       " 'attentive',\n",
       " 'majesty',\n",
       " 'adaptable',\n",
       " 'glisten',\n",
       " 'ennoble',\n",
       " 'endearing',\n",
       " 'recommendations',\n",
       " 'lyrical',\n",
       " 'wisdom',\n",
       " 'empathy',\n",
       " 'adjustable',\n",
       " 'intelligence',\n",
       " 'renowned',\n",
       " 'amity',\n",
       " 'correctly',\n",
       " 'thank',\n",
       " 'mastery',\n",
       " 'favour',\n",
       " 'insightful',\n",
       " 'astounding',\n",
       " 'tops',\n",
       " 'delightfulness',\n",
       " 'outperforming',\n",
       " 'gained',\n",
       " 'perfectly',\n",
       " 'thrillingly',\n",
       " 'adored',\n",
       " 'beckon',\n",
       " 'carefree',\n",
       " 'intelligible',\n",
       " 'eyecatch',\n",
       " 'prize',\n",
       " 'justly',\n",
       " 'credible',\n",
       " 'endorsed',\n",
       " 'glowingly',\n",
       " 'lead',\n",
       " 'clear',\n",
       " 'prudent',\n",
       " 'smartly',\n",
       " 'tougher',\n",
       " 'graciousness',\n",
       " 'daringly',\n",
       " 'exceptionally',\n",
       " 'abounds',\n",
       " 'fanfare',\n",
       " 'panoramic',\n",
       " 'well-connected',\n",
       " 'dummy-proof',\n",
       " 'amiable',\n",
       " 'dashing',\n",
       " 'enchanted',\n",
       " 'reassurance',\n",
       " 'upgradable',\n",
       " 'defeat',\n",
       " 'fulfillment',\n",
       " 'rosy',\n",
       " 'liked',\n",
       " 'enjoyment',\n",
       " 'heavenly',\n",
       " 'upgradeable',\n",
       " 'fancinating',\n",
       " 'slammin',\n",
       " 'warmly',\n",
       " 'blameless',\n",
       " 'marvellous',\n",
       " 'counter-attacks',\n",
       " 'exceeds',\n",
       " 'dirt-cheap',\n",
       " 'handsomely',\n",
       " 'softer',\n",
       " 'pros',\n",
       " 'heroine',\n",
       " 'diversified',\n",
       " 'breathtaking',\n",
       " 'joyfully',\n",
       " 'marvelled',\n",
       " 'charitable',\n",
       " 'plusses',\n",
       " 'unwavering',\n",
       " 'staunchly',\n",
       " 'benefactor',\n",
       " 'fabulously',\n",
       " 'humorous',\n",
       " 'supporter',\n",
       " 'loyalty',\n",
       " 'evocative',\n",
       " 'coherent',\n",
       " 'danken',\n",
       " 'easiness',\n",
       " 'loves',\n",
       " 'razor-sharp',\n",
       " 'snazzy',\n",
       " 'favorited',\n",
       " 'enjoy',\n",
       " 'openly',\n",
       " 'dreamland',\n",
       " 'destiny',\n",
       " 'dotingly',\n",
       " 'tempting',\n",
       " 'excites',\n",
       " 'incredibly',\n",
       " 'merit',\n",
       " 'precious',\n",
       " 'well-managed',\n",
       " 'prodigiously',\n",
       " 'love',\n",
       " 'adorer',\n",
       " 'admirable',\n",
       " 'endorsement',\n",
       " 'priceless',\n",
       " 'refreshing',\n",
       " 'appreciates',\n",
       " 'qualify',\n",
       " 'gleefully',\n",
       " 'peerless',\n",
       " 'fine-looking',\n",
       " 'quicker',\n",
       " 'humourous',\n",
       " 'reaffirm',\n",
       " 'intriguing',\n",
       " 'expertly',\n",
       " 'indebted',\n",
       " 'talented',\n",
       " 'guarantee',\n",
       " 'awed',\n",
       " 'generosity',\n",
       " 'keenly',\n",
       " 'affirmative',\n",
       " 'decisive',\n",
       " 'law-abiding',\n",
       " 'speedily',\n",
       " 'inspirational',\n",
       " 'staunchness',\n",
       " 'reform',\n",
       " 'awesomely',\n",
       " 'infallible',\n",
       " 'defender',\n",
       " 'enticing',\n",
       " 'faith',\n",
       " 'blithe',\n",
       " 'commendable',\n",
       " 'assurances',\n",
       " 'surpass',\n",
       " 'fresher',\n",
       " 'steadiest',\n",
       " 'well-being',\n",
       " 'engrossing',\n",
       " 'magnanimous',\n",
       " 'wows',\n",
       " 'pamperedly',\n",
       " 'gentlest',\n",
       " 'vivacious',\n",
       " 'homage',\n",
       " 'charisma',\n",
       " 'exemplary',\n",
       " 'fervidly',\n",
       " 'issue-free',\n",
       " 'nice',\n",
       " 'merriness',\n",
       " 'survivor',\n",
       " 'vibrant',\n",
       " 'humor',\n",
       " 'enough',\n",
       " 'bargain',\n",
       " 'productively',\n",
       " 'exemplar',\n",
       " 'poignant',\n",
       " 'dominate',\n",
       " 'agreeable',\n",
       " 'feasible',\n",
       " 'promised',\n",
       " 'aver',\n",
       " 'famously',\n",
       " 'keen',\n",
       " 'obsessions',\n",
       " 'shimmeringly',\n",
       " 'unrivaled',\n",
       " 'low-cost',\n",
       " 'quaint',\n",
       " 'dead-on',\n",
       " 'examplary',\n",
       " 'encouragement',\n",
       " 'peaceable',\n",
       " 'peppy',\n",
       " 'applaud',\n",
       " 'zeal',\n",
       " 'respectful',\n",
       " 'simplified',\n",
       " 'resourceful',\n",
       " 'talents',\n",
       " 'enthralled',\n",
       " 'fashionably',\n",
       " 'toll-free',\n",
       " 'dumbfounding',\n",
       " 'accomplished',\n",
       " 'supported',\n",
       " 'enviably',\n",
       " 'blissfully',\n",
       " 'preeminent',\n",
       " 'swiftness',\n",
       " 'worth',\n",
       " 'feisty',\n",
       " 'reforming',\n",
       " 'better',\n",
       " 'merciful',\n",
       " 'cheapest',\n",
       " 'calm',\n",
       " 'fortune',\n",
       " 'congratulate',\n",
       " 'easiest',\n",
       " 'eloquently',\n",
       " 'marvelous',\n",
       " 'flatter',\n",
       " 'resourcefulness',\n",
       " 'roomy',\n",
       " 'useful',\n",
       " 'approve',\n",
       " 'exquisitely',\n",
       " 'facilitate',\n",
       " 'proficient',\n",
       " 'excellency',\n",
       " 'ebullience',\n",
       " 'articulate',\n",
       " 'tidy',\n",
       " 'gracefully',\n",
       " 'infallibility',\n",
       " 'benefit',\n",
       " 'trustingly',\n",
       " 'prolific',\n",
       " 'radiance',\n",
       " 'exult',\n",
       " 'accurately',\n",
       " 'fascination',\n",
       " 'booming',\n",
       " 'cashback',\n",
       " 'friendly',\n",
       " 'ecstasies',\n",
       " 'illustrious',\n",
       " 'enhance',\n",
       " 'sensations',\n",
       " 'courteous',\n",
       " 'twinkly',\n",
       " 'poised',\n",
       " 'poeticize',\n",
       " 'stylishly',\n",
       " 'cherub',\n",
       " 'worthiness',\n",
       " 'warmer',\n",
       " 'enraptured',\n",
       " 'smiling',\n",
       " 'amazement',\n",
       " 'snappy',\n",
       " 'courageously',\n",
       " 'optimistic',\n",
       " 'lively',\n",
       " 'inspire',\n",
       " 'rejuvenate',\n",
       " 'reforms',\n",
       " 'excellant',\n",
       " 'engaging',\n",
       " 'reliable',\n",
       " 'swank',\n",
       " 'equitable',\n",
       " 'realistic',\n",
       " 'redeeming',\n",
       " 'rejoicing',\n",
       " 'world-famous',\n",
       " 'yay',\n",
       " 'outstrip',\n",
       " 'wondrous',\n",
       " 'politeness',\n",
       " 'harmoniously',\n",
       " 'prefer',\n",
       " 'blissful',\n",
       " 'brilliantly',\n",
       " 'easy-to-use',\n",
       " 'masterfully',\n",
       " 'avid',\n",
       " 'fluent',\n",
       " 'fortitude',\n",
       " 'benefits',\n",
       " 'admiration',\n",
       " 'beneficiary',\n",
       " 'grandeur',\n",
       " 'elate',\n",
       " 'buoyant',\n",
       " 'encouraging',\n",
       " 'comforting',\n",
       " 'advantage',\n",
       " 'finely',\n",
       " 'refined',\n",
       " 'eminence',\n",
       " 'desirable',\n",
       " 'magnificence',\n",
       " 'patience',\n",
       " 'steady',\n",
       " 'heros',\n",
       " 'backbone',\n",
       " 'happiness',\n",
       " 'seasoned',\n",
       " 'easy',\n",
       " 'dazzled',\n",
       " 'streamlined',\n",
       " 'dynamic',\n",
       " 'exultation',\n",
       " 'willing',\n",
       " 'clarity',\n",
       " 'easygoing',\n",
       " 'intrigue',\n",
       " 'happy',\n",
       " 'surmount',\n",
       " 'right',\n",
       " 'sparkle',\n",
       " 'knowledgeable',\n",
       " 'capably',\n",
       " 'realizable',\n",
       " 'brilliant',\n",
       " 'all-around',\n",
       " 'benifits',\n",
       " 'transparent',\n",
       " 'tempt',\n",
       " 'euphoria',\n",
       " 'accomplish',\n",
       " 'surreal',\n",
       " 'master',\n",
       " 'outwit',\n",
       " 'invincibility',\n",
       " 'fantastically',\n",
       " 'beutifully',\n",
       " 'smarter',\n",
       " 'remarkably',\n",
       " 'ease',\n",
       " 'abundant',\n",
       " 'mercy',\n",
       " 'inestimable',\n",
       " 'amenable',\n",
       " 'invaluable',\n",
       " 'ameliorate',\n",
       " 'marvelousness',\n",
       " 'flutter',\n",
       " 'accomplishments',\n",
       " 'rockstars',\n",
       " 'glimmering',\n",
       " 'memorable',\n",
       " 'outstandingly',\n",
       " 'benevolence',\n",
       " 'inviolable',\n",
       " 'savings',\n",
       " 'flatteringly',\n",
       " 'distinguished',\n",
       " 'nobly',\n",
       " 'dependable',\n",
       " 'nicer',\n",
       " 'laud',\n",
       " 'exquisite',\n",
       " 'profoundly',\n",
       " 'exhilaration',\n",
       " 'proving',\n",
       " 'richer',\n",
       " 'flawlessly',\n",
       " 'unselfish',\n",
       " 'trusting',\n",
       " 'sincerity',\n",
       " 'devout',\n",
       " 'sensational',\n",
       " 'stabilize',\n",
       " 'jubilant',\n",
       " 'earnestness',\n",
       " 'enviousness',\n",
       " 'peps',\n",
       " 'bonus',\n",
       " 'gratifies',\n",
       " 'beautify',\n",
       " 'bright',\n",
       " 'zenith',\n",
       " 'a+',\n",
       " 'great',\n",
       " 'spacious',\n",
       " 'favorite',\n",
       " 'subsidizes',\n",
       " 'enthuse',\n",
       " 'galore',\n",
       " 'accolade',\n",
       " 'low-priced',\n",
       " 'recommended',\n",
       " 'unbeatable',\n",
       " 'courageous',\n",
       " 'captivating',\n",
       " 'modest',\n",
       " 'extraordinarily',\n",
       " 'advocated',\n",
       " 'valuable',\n",
       " 'lighter',\n",
       " 'pampers',\n",
       " 'bonny',\n",
       " 'guiltless',\n",
       " 'toughest',\n",
       " 'enthusiast',\n",
       " 'best-selling',\n",
       " 'gaining',\n",
       " 'entranced',\n",
       " 'amiability',\n",
       " 'excallent',\n",
       " 'visionary',\n",
       " 'trust',\n",
       " 'good',\n",
       " 'astonished',\n",
       " 'reward',\n",
       " 'stunningly',\n",
       " 'subsidized',\n",
       " 'painlessly',\n",
       " 'happier',\n",
       " 'competitive',\n",
       " 'irreplaceable',\n",
       " 'charmingly',\n",
       " 'suffices',\n",
       " 'fortuitous',\n",
       " 'thoughtfully',\n",
       " 'erudite',\n",
       " 'sweetheart',\n",
       " 'luckier',\n",
       " 'favored',\n",
       " 'raptureous',\n",
       " 'satisfactory',\n",
       " 'satisfactorily',\n",
       " 'eased',\n",
       " 'ovation',\n",
       " 'phenomenal',\n",
       " 'acclaim',\n",
       " 'record-setting',\n",
       " 'rectification',\n",
       " 'mesmerize',\n",
       " 'spellbinding',\n",
       " 'helping',\n",
       " 'sensible',\n",
       " 'elevate',\n",
       " 'triumphal',\n",
       " 'cozy',\n",
       " 'fast',\n",
       " 'charismatic',\n",
       " 'incredible',\n",
       " 'terrific',\n",
       " 'rejoicingly',\n",
       " 'valor',\n",
       " 'protection',\n",
       " 'super',\n",
       " 'felicitous',\n",
       " 'compliment',\n",
       " 'tender',\n",
       " 'trouble-free',\n",
       " 'terrifically',\n",
       " 'aspiration',\n",
       " 'refunded',\n",
       " 'exultant',\n",
       " 'hopeful',\n",
       " 'noteworthy',\n",
       " 'supurb',\n",
       " 'reformed',\n",
       " 'consummate',\n",
       " 'redeem',\n",
       " 'skillfully',\n",
       " 'sweeten',\n",
       " 'overtaken',\n",
       " 'supporting',\n",
       " 'clean',\n",
       " 'brightest',\n",
       " 'indulgent',\n",
       " 'godsend',\n",
       " 'survival',\n",
       " 'delightful',\n",
       " 'wisely',\n",
       " 'sweet',\n",
       " 'heaven',\n",
       " 'deginified',\n",
       " 'wins',\n",
       " 'smiles',\n",
       " 'skillful',\n",
       " 'jubilantly',\n",
       " 'lavish',\n",
       " 'warmhearted',\n",
       " 'amply',\n",
       " 'dignity',\n",
       " 'brotherly',\n",
       " 'passionate',\n",
       " 'exceeding',\n",
       " 'variety',\n",
       " 'sane',\n",
       " 'examplar',\n",
       " 'valiant',\n",
       " 'thinner',\n",
       " 'crisp',\n",
       " 'peacefully',\n",
       " 'succeeds',\n",
       " 'darling',\n",
       " 'genius',\n",
       " 'integral',\n",
       " 'glistening',\n",
       " 'afford',\n",
       " 'breeze',\n",
       " 'legendary',\n",
       " 'satisfies',\n",
       " 'supports',\n",
       " 'proves',\n",
       " 'works',\n",
       " 'romantic',\n",
       " 'gratifying',\n",
       " 'innocuous',\n",
       " 'hallowed',\n",
       " 'effective',\n",
       " 'dextrous',\n",
       " 'immense',\n",
       " 'wonderfully',\n",
       " 'respite',\n",
       " 'agilely',\n",
       " 'eventful',\n",
       " 'wonders',\n",
       " 'audible',\n",
       " 'rejoice',\n",
       " 'enchanting',\n",
       " 'astounded',\n",
       " 'uplifting',\n",
       " 'creative',\n",
       " 'bountiful',\n",
       " 'contentment',\n",
       " 'smartest',\n",
       " 'stimulate',\n",
       " 'prominent',\n",
       " ...}"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "positive_words"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "\n",
    "def calculate_score(text):\n",
    "   \n",
    "    text_words = set(text.split())\n",
    "    word_set = set(text_words)\n",
    "\n",
    "    \n",
    "    score = len(text_words.intersection(word_set))\n",
    "\n",
    "    return score\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Rising IT cities and its impact on the economy, environment, infrastructure, and city life by the year 2040. - Blackcoffer Insights\n",
      "\n",
      "Automate the Data Management Process\n",
      "Realtime Kibana Dashboard for a financial tech firm\n",
      "Data Management, ETL, and Data Automation\n",
      "Data Management – EGEAS\n",
      "How To Secure (SSL) Nginx with Let’s Encrypt on Ubuntu (Cloud VM, GCP, AWS, Azure, Linode) and Add Domain\n",
      "Deploy and view React app(Nextjs) on cloud VM such as GCP, AWS, Azure, Linode\n",
      "Deploy Nodejs app on a cloud VM such as GCP, AWS, Azure, Linode\n",
      "Grafana Dashboard – Oscar Awards\n",
      "Rising IT cities and its impact on the economy, environment, infrastructure, and city life by the year 2040.\n",
      "Rising IT Cities and Their Impact on the Economy, Environment, Infrastructure, and City Life in Future\n",
      "Internet Demand’s Evolution, Communication Impact, and 2035’s Alternative Pathways\n",
      "Rise of Cybercrime and its Effect in upcoming Future\n",
      "AI/ML and Predictive Modeling\n",
      "Solution for Contact Centre Problems\n",
      "How to Setup Custom Domain for Google App Engine Application?\n",
      "Code Review Checklist\n",
      "We have seen a huge development and dependence of people on technology in recent years. We have also seen the development of AI and ChatGPT in recent years. So it is a normal thing that we will become fully dependent on technology by 2040. Information technology will be a major power for all the developing nations. As a member of a developing nation, India is rapidly growing its IT base. It has also grown some IT cities which will be the major control centres for Information technology by 2040.\n",
      "Rising IT cities\n",
      "Kolkata:- Kolkata in West Bengal is an emerging major IT hub. The new Kolkata i.e. Saltlake Sector  5, New town, Rajarhat area of Kolkata is a major IT hub. The government is giving the software companies land at almost free of cost to set up the companies there. Many large companies like Google, Microsoft, IBM, Infosys and others have set up their companies here. Kolkata has a market base of billions of dollars and is doing a great job of boosting the national economy.\n",
      "Impact on Economy\n",
      "There is a huge impact of the rising IT cities on our economy. Some of the effects are-\n",
      "Impact on Environment\n",
      "The rising IT cities will create a huge impact on the environment, the maximum of which will be harmful effects. The impact of rising IT cities on the environment is-\n",
      "Impact on infrastructure\n",
      "There are many contributions of the IT cities on infrastructure.  They are-\n",
      "Impact on city life\n",
      "With the growth of IT cities, more people will get jobs and will earn more. So the purchasing power of the people will increase. People will lead a better lifestyle. They will buy things of good brand value. The tastes and preferences of people will also change. The human development index is going to increase. People will buy good quality food and good quality cars. So the food, automobile and many other industries are going to increase. So there will be a huge impact on city life by 2040.\n",
      "We provide intelligence, accelerate innovation and implement technology with extraordinary breadth and depth global insights into the big data,data-driven dashboards, applications development, and information management for organizations through combining unique, specialist services and high-lvel human expertise.\n"
     ]
    }
   ],
   "source": [
    "file_path = \"C:/Users/rohit/scraping/txt_files/1.txt\"  # Replace with the path to your text file\n",
    "\n",
    "# Open the file in read mode\n",
    "with open(file_path, 'r', encoding='utf-8') as file:\n",
    "    # Read the entire content of the file\n",
    "    file_content = file.read()\n",
    "\n",
    "# Now, file_content contains the contents of the text file\n",
    "print(file_content)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Positive Score: 289\n"
     ]
    }
   ],
   "source": [
    "\n",
    "positive_score = calculate_score(file_content)\n",
    "print(f\"Positive Score: {positive_score}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Combined stop words saved to 'combined_stopwords.txt'.\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "\n",
    "# Specify the directory containing stop word files\n",
    "directory_path = \"C:/Users/rohit/scraping/balckcoffer/StopWords\"\n",
    "\n",
    "# Get a list of all files in the directory\n",
    "stop_words_files = [f for f in os.listdir(directory_path) if os.path.isfile(os.path.join(directory_path, f))]\n",
    "\n",
    "all_stop_words = set()\n",
    "\n",
    "# Read stop words from each file and combine them\n",
    "for file in stop_words_files:\n",
    "    file_path = os.path.join(directory_path, file)\n",
    "    with open(file_path, 'r') as f:\n",
    "        stop_words = set(word.strip() for word in f)\n",
    "        all_stop_words.update(stop_words)\n",
    "\n",
    "# Write combined stop words to a new file\n",
    "output_file = \"combined_stopwords.txt\"\n",
    "with open(output_file, 'w') as f:\n",
    "    for word in all_stop_words:\n",
    "        f.write(word + '\\n')\n",
    "\n",
    "print(f\"Combined stop words saved to '{output_file}'.\")\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "\n",
    "def read_words(file_path):\n",
    "    words = set()\n",
    "    with open(file_path, 'r', encoding='utf-8', errors='ignore') as file:\n",
    "        for line in file:\n",
    "            words.add(line.strip())\n",
    "    return words\n",
    "\n",
    "def remove_words(input_file_path, stopwords_file_path, output_file_path):\n",
    "    # Read words from the files\n",
    "    words_to_remove = read_words(stopwords_file_path)\n",
    "\n",
    "    with open(input_file_path, 'r', encoding='utf-8', errors='ignore') as input_file, \\\n",
    "         open(output_file_path, 'w', encoding='utf-8', errors='ignore') as output_file:\n",
    "        for line in input_file:\n",
    "            # Remove words from the line\n",
    "            updated_line = ' '.join(word for word in line.split() if word not in words_to_remove)\n",
    "            output_file.write(updated_line + '\\n')\n",
    "\n",
    "# Specify the folder containing text files\n",
    "folder_path = \"C:/Users/rohit/scraping/txt_files\"\n",
    "\n",
    "# Specify the folder for output files\n",
    "output_folder = \"C:/Users/rohit/scraping/txt_files_modified\"\n",
    "\n",
    "# Create the output folder if it doesn't exist\n",
    "if not os.path.exists(output_folder):\n",
    "    os.makedirs(output_folder)\n",
    "\n",
    "# Loop through all text files in the folder\n",
    "for filename in os.listdir(folder_path):\n",
    "    if filename.endswith(\".txt\"):\n",
    "        input_file_path = os.path.join(folder_path, filename)\n",
    "        output_file_path = os.path.join(output_folder, filename)\n",
    "        stopwords_file_path = \"C:/Users/rohit/scraping/combined_stopwords.txt\"\n",
    "\n",
    "        remove_words(input_file_path, stopwords_file_path, output_file_path)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [
    {
     "ename": "KeyError",
     "evalue": "'File'",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mKeyError\u001b[0m                                  Traceback (most recent call last)",
      "File \u001b[1;32mc:\\Users\\rohit\\scraping\\soup\\Lib\\site-packages\\pandas\\core\\indexes\\base.py:3791\u001b[0m, in \u001b[0;36mIndex.get_loc\u001b[1;34m(self, key)\u001b[0m\n\u001b[0;32m   3790\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[1;32m-> 3791\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_engine\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mget_loc\u001b[49m\u001b[43m(\u001b[49m\u001b[43mcasted_key\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m   3792\u001b[0m \u001b[38;5;28;01mexcept\u001b[39;00m \u001b[38;5;167;01mKeyError\u001b[39;00m \u001b[38;5;28;01mas\u001b[39;00m err:\n",
      "File \u001b[1;32mindex.pyx:152\u001b[0m, in \u001b[0;36mpandas._libs.index.IndexEngine.get_loc\u001b[1;34m()\u001b[0m\n",
      "File \u001b[1;32mindex.pyx:181\u001b[0m, in \u001b[0;36mpandas._libs.index.IndexEngine.get_loc\u001b[1;34m()\u001b[0m\n",
      "File \u001b[1;32mpandas\\_libs\\hashtable_class_helper.pxi:7080\u001b[0m, in \u001b[0;36mpandas._libs.hashtable.PyObjectHashTable.get_item\u001b[1;34m()\u001b[0m\n",
      "File \u001b[1;32mpandas\\_libs\\hashtable_class_helper.pxi:7088\u001b[0m, in \u001b[0;36mpandas._libs.hashtable.PyObjectHashTable.get_item\u001b[1;34m()\u001b[0m\n",
      "\u001b[1;31mKeyError\u001b[0m: 'File'",
      "\nThe above exception was the direct cause of the following exception:\n",
      "\u001b[1;31mKeyError\u001b[0m                                  Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[42], line 33\u001b[0m\n\u001b[0;32m     31\u001b[0m \u001b[38;5;66;03m# Calculate scores for each file\u001b[39;00m\n\u001b[0;32m     32\u001b[0m \u001b[38;5;28;01mfor\u001b[39;00m index, row \u001b[38;5;129;01min\u001b[39;00m links_df\u001b[38;5;241m.\u001b[39miterrows():\n\u001b[1;32m---> 33\u001b[0m     file_name \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mstr\u001b[39m(row[\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mFile\u001b[39m\u001b[38;5;124m\"\u001b[39m]) \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m pd\u001b[38;5;241m.\u001b[39misna(\u001b[43mrow\u001b[49m\u001b[43m[\u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mFile\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m]\u001b[49m) \u001b[38;5;28;01melse\u001b[39;00m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m\"\u001b[39m  \u001b[38;5;66;03m# Convert to string and handle NaN\u001b[39;00m\n\u001b[0;32m     35\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m file_name:  \u001b[38;5;66;03m# Check if file_name is not empty\u001b[39;00m\n\u001b[0;32m     36\u001b[0m         file_path \u001b[38;5;241m=\u001b[39m os\u001b[38;5;241m.\u001b[39mpath\u001b[38;5;241m.\u001b[39mjoin(modified_folder, file_name)\n",
      "File \u001b[1;32mc:\\Users\\rohit\\scraping\\soup\\Lib\\site-packages\\pandas\\core\\series.py:1040\u001b[0m, in \u001b[0;36mSeries.__getitem__\u001b[1;34m(self, key)\u001b[0m\n\u001b[0;32m   1037\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_values[key]\n\u001b[0;32m   1039\u001b[0m \u001b[38;5;28;01melif\u001b[39;00m key_is_scalar:\n\u001b[1;32m-> 1040\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_get_value\u001b[49m\u001b[43m(\u001b[49m\u001b[43mkey\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m   1042\u001b[0m \u001b[38;5;66;03m# Convert generator to list before going through hashable part\u001b[39;00m\n\u001b[0;32m   1043\u001b[0m \u001b[38;5;66;03m# (We will iterate through the generator there to check for slices)\u001b[39;00m\n\u001b[0;32m   1044\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m is_iterator(key):\n",
      "File \u001b[1;32mc:\\Users\\rohit\\scraping\\soup\\Lib\\site-packages\\pandas\\core\\series.py:1156\u001b[0m, in \u001b[0;36mSeries._get_value\u001b[1;34m(self, label, takeable)\u001b[0m\n\u001b[0;32m   1153\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_values[label]\n\u001b[0;32m   1155\u001b[0m \u001b[38;5;66;03m# Similar to Index.get_value, but we do not fall back to positional\u001b[39;00m\n\u001b[1;32m-> 1156\u001b[0m loc \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mindex\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mget_loc\u001b[49m\u001b[43m(\u001b[49m\u001b[43mlabel\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m   1158\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m is_integer(loc):\n\u001b[0;32m   1159\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_values[loc]\n",
      "File \u001b[1;32mc:\\Users\\rohit\\scraping\\soup\\Lib\\site-packages\\pandas\\core\\indexes\\base.py:3798\u001b[0m, in \u001b[0;36mIndex.get_loc\u001b[1;34m(self, key)\u001b[0m\n\u001b[0;32m   3793\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28misinstance\u001b[39m(casted_key, \u001b[38;5;28mslice\u001b[39m) \u001b[38;5;129;01mor\u001b[39;00m (\n\u001b[0;32m   3794\u001b[0m         \u001b[38;5;28misinstance\u001b[39m(casted_key, abc\u001b[38;5;241m.\u001b[39mIterable)\n\u001b[0;32m   3795\u001b[0m         \u001b[38;5;129;01mand\u001b[39;00m \u001b[38;5;28many\u001b[39m(\u001b[38;5;28misinstance\u001b[39m(x, \u001b[38;5;28mslice\u001b[39m) \u001b[38;5;28;01mfor\u001b[39;00m x \u001b[38;5;129;01min\u001b[39;00m casted_key)\n\u001b[0;32m   3796\u001b[0m     ):\n\u001b[0;32m   3797\u001b[0m         \u001b[38;5;28;01mraise\u001b[39;00m InvalidIndexError(key)\n\u001b[1;32m-> 3798\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mKeyError\u001b[39;00m(key) \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01merr\u001b[39;00m\n\u001b[0;32m   3799\u001b[0m \u001b[38;5;28;01mexcept\u001b[39;00m \u001b[38;5;167;01mTypeError\u001b[39;00m:\n\u001b[0;32m   3800\u001b[0m     \u001b[38;5;66;03m# If we have a listlike key, _check_indexing_error will raise\u001b[39;00m\n\u001b[0;32m   3801\u001b[0m     \u001b[38;5;66;03m#  InvalidIndexError. Otherwise we fall through and re-raise\u001b[39;00m\n\u001b[0;32m   3802\u001b[0m     \u001b[38;5;66;03m#  the TypeError.\u001b[39;00m\n\u001b[0;32m   3803\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_check_indexing_error(key)\n",
      "\u001b[1;31mKeyError\u001b[0m: 'File'"
     ]
    }
   ],
   "source": [
    "import os\n",
    "import pandas as pd\n",
    "\n",
    "def calculate_score(text, word_set):\n",
    "    text_words = set(text.split())\n",
    "    score = len(text_words.intersection(word_set))\n",
    "    return score\n",
    "\n",
    "def load_word_set(file_path, encoding='utf-8'):\n",
    "    with open(file_path, 'r', encoding=encoding, errors='replace') as file:\n",
    "        words = file.read().split()\n",
    "    return set(words)\n",
    "\n",
    "# Take user input for file paths\n",
    "positive_words_file = \"C:/Users/rohit/scraping/balckcoffer/MasterDictionary/positive-words.txt\"\n",
    "negative_words_file = \"C:/Users/rohit/scraping/balckcoffer/MasterDictionary/negative-words.txt\"\n",
    "modified_folder = \"C:/Users/rohit/scraping/txt_files_modified\"  # Change this to the path of your modified folder\n",
    "links_csv_path = \"C:/Users/rohit/scraping/links.csv\" # Change this to the path of your links CSV file\n",
    "\n",
    "positive_word_set = load_word_set(positive_words_file, encoding='latin-1')\n",
    "negative_word_set = load_word_set(negative_words_file, encoding='latin-1')\n",
    "\n",
    "# Load the existing links CSV file\n",
    "links_df = pd.read_csv(links_csv_path)\n",
    "\n",
    "# Create empty lists for positive and negative scores\n",
    "positive_scores = []\n",
    "negative_scores = []\n",
    "\n",
    "# Calculate scores for each file\n",
    "for index, row in links_df.iterrows():\n",
    "    url_id = row[\"URL_ID\"]\n",
    "    file_name = f\"{url_id}.txt\"  # Assuming file names are based on URL_ID\n",
    "    \n",
    "    file_path = os.path.join(modified_folder, file_name)\n",
    "\n",
    "    if os.path.exists(file_path):\n",
    "        with open(file_path, 'r', encoding='utf-8') as file:\n",
    "            content = file.read()\n",
    "\n",
    "        positive_score = calculate_score(content, positive_word_set)\n",
    "        negative_score = calculate_score(content, negative_word_set)\n",
    "\n",
    "        positive_scores.append(positive_score)\n",
    "        negative_scores.append(negative_score)\n",
    "    else:\n",
    "        # Handle the case where the file does not exist\n",
    "        print(f\"File not found for URL_ID {url_id}. Check the directory structure and file naming convention.\")\n",
    "\n",
    "# Add the lists as new columns to the DataFrame\n",
    "links_df[\"Positive Score\"] = positive_scores\n",
    "links_df[\"Negative Score\"] = negative_scores\n",
    "\n",
    "# Save the updated DataFrame to the links CSV file\n",
    "links_df.to_csv(links_csv_path, index=False)\n",
    "\n",
    "print(f\"Scores added to {links_csv_path}\")\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [],
   "source": [
    "df=pd.read_csv('links.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "ename": "KeyError",
     "evalue": "\"['Positive Score', 'Negative Score', 'File'] not found in axis\"",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mKeyError\u001b[0m                                  Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[24], line 1\u001b[0m\n\u001b[1;32m----> 1\u001b[0m \u001b[43mdf\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mdrop\u001b[49m\u001b[43m(\u001b[49m\u001b[43m[\u001b[49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[38;5;124;43mPositive Score\u001b[39;49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[43m,\u001b[49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[38;5;124;43mNegative Score\u001b[39;49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[43m,\u001b[49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[38;5;124;43mFile\u001b[39;49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[43m]\u001b[49m\u001b[43m,\u001b[49m\u001b[43maxis\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;241;43m1\u001b[39;49m\u001b[43m)\u001b[49m\n",
      "File \u001b[1;32mc:\\Users\\rohit\\scraping\\soup\\Lib\\site-packages\\pandas\\core\\frame.py:5344\u001b[0m, in \u001b[0;36mDataFrame.drop\u001b[1;34m(self, labels, axis, index, columns, level, inplace, errors)\u001b[0m\n\u001b[0;32m   5196\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mdrop\u001b[39m(\n\u001b[0;32m   5197\u001b[0m     \u001b[38;5;28mself\u001b[39m,\n\u001b[0;32m   5198\u001b[0m     labels: IndexLabel \u001b[38;5;241m|\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m,\n\u001b[1;32m   (...)\u001b[0m\n\u001b[0;32m   5205\u001b[0m     errors: IgnoreRaise \u001b[38;5;241m=\u001b[39m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mraise\u001b[39m\u001b[38;5;124m\"\u001b[39m,\n\u001b[0;32m   5206\u001b[0m ) \u001b[38;5;241m-\u001b[39m\u001b[38;5;241m>\u001b[39m DataFrame \u001b[38;5;241m|\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[0;32m   5207\u001b[0m \u001b[38;5;250m    \u001b[39m\u001b[38;5;124;03m\"\"\"\u001b[39;00m\n\u001b[0;32m   5208\u001b[0m \u001b[38;5;124;03m    Drop specified labels from rows or columns.\u001b[39;00m\n\u001b[0;32m   5209\u001b[0m \n\u001b[1;32m   (...)\u001b[0m\n\u001b[0;32m   5342\u001b[0m \u001b[38;5;124;03m            weight  1.0     0.8\u001b[39;00m\n\u001b[0;32m   5343\u001b[0m \u001b[38;5;124;03m    \"\"\"\u001b[39;00m\n\u001b[1;32m-> 5344\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43msuper\u001b[39;49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mdrop\u001b[49m\u001b[43m(\u001b[49m\n\u001b[0;32m   5345\u001b[0m \u001b[43m        \u001b[49m\u001b[43mlabels\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mlabels\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m   5346\u001b[0m \u001b[43m        \u001b[49m\u001b[43maxis\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43maxis\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m   5347\u001b[0m \u001b[43m        \u001b[49m\u001b[43mindex\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mindex\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m   5348\u001b[0m \u001b[43m        \u001b[49m\u001b[43mcolumns\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mcolumns\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m   5349\u001b[0m \u001b[43m        \u001b[49m\u001b[43mlevel\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mlevel\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m   5350\u001b[0m \u001b[43m        \u001b[49m\u001b[43minplace\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43minplace\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m   5351\u001b[0m \u001b[43m        \u001b[49m\u001b[43merrors\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43merrors\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m   5352\u001b[0m \u001b[43m    \u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[1;32mc:\\Users\\rohit\\scraping\\soup\\Lib\\site-packages\\pandas\\core\\generic.py:4711\u001b[0m, in \u001b[0;36mNDFrame.drop\u001b[1;34m(self, labels, axis, index, columns, level, inplace, errors)\u001b[0m\n\u001b[0;32m   4709\u001b[0m \u001b[38;5;28;01mfor\u001b[39;00m axis, labels \u001b[38;5;129;01min\u001b[39;00m axes\u001b[38;5;241m.\u001b[39mitems():\n\u001b[0;32m   4710\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m labels \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[1;32m-> 4711\u001b[0m         obj \u001b[38;5;241m=\u001b[39m \u001b[43mobj\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_drop_axis\u001b[49m\u001b[43m(\u001b[49m\u001b[43mlabels\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43maxis\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mlevel\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mlevel\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43merrors\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43merrors\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m   4713\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m inplace:\n\u001b[0;32m   4714\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_update_inplace(obj)\n",
      "File \u001b[1;32mc:\\Users\\rohit\\scraping\\soup\\Lib\\site-packages\\pandas\\core\\generic.py:4753\u001b[0m, in \u001b[0;36mNDFrame._drop_axis\u001b[1;34m(self, labels, axis, level, errors, only_slice)\u001b[0m\n\u001b[0;32m   4751\u001b[0m         new_axis \u001b[38;5;241m=\u001b[39m axis\u001b[38;5;241m.\u001b[39mdrop(labels, level\u001b[38;5;241m=\u001b[39mlevel, errors\u001b[38;5;241m=\u001b[39merrors)\n\u001b[0;32m   4752\u001b[0m     \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[1;32m-> 4753\u001b[0m         new_axis \u001b[38;5;241m=\u001b[39m \u001b[43maxis\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mdrop\u001b[49m\u001b[43m(\u001b[49m\u001b[43mlabels\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43merrors\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43merrors\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m   4754\u001b[0m     indexer \u001b[38;5;241m=\u001b[39m axis\u001b[38;5;241m.\u001b[39mget_indexer(new_axis)\n\u001b[0;32m   4756\u001b[0m \u001b[38;5;66;03m# Case for non-unique axis\u001b[39;00m\n\u001b[0;32m   4757\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n",
      "File \u001b[1;32mc:\\Users\\rohit\\scraping\\soup\\Lib\\site-packages\\pandas\\core\\indexes\\base.py:7000\u001b[0m, in \u001b[0;36mIndex.drop\u001b[1;34m(self, labels, errors)\u001b[0m\n\u001b[0;32m   6998\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m mask\u001b[38;5;241m.\u001b[39many():\n\u001b[0;32m   6999\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m errors \u001b[38;5;241m!=\u001b[39m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mignore\u001b[39m\u001b[38;5;124m\"\u001b[39m:\n\u001b[1;32m-> 7000\u001b[0m         \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mKeyError\u001b[39;00m(\u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;132;01m{\u001b[39;00mlabels[mask]\u001b[38;5;241m.\u001b[39mtolist()\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m not found in axis\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n\u001b[0;32m   7001\u001b[0m     indexer \u001b[38;5;241m=\u001b[39m indexer[\u001b[38;5;241m~\u001b[39mmask]\n\u001b[0;32m   7002\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mdelete(indexer)\n",
      "\u001b[1;31mKeyError\u001b[0m: \"['Positive Score', 'Negative Score', 'File'] not found in axis\""
     ]
    }
   ],
   "source": [
    "df.drop(['Positive Score','Negative Score','File'],axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>URL_ID</th>\n",
       "      <th>URL</th>\n",
       "      <th>Positive Score</th>\n",
       "      <th>Negative Score</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>blackassign0001</td>\n",
       "      <td>https://insights.blackcoffer.com/rising-it-cit...</td>\n",
       "      <td>6</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>blackassign0002</td>\n",
       "      <td>https://insights.blackcoffer.com/rising-it-cit...</td>\n",
       "      <td>36</td>\n",
       "      <td>18</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>blackassign0003</td>\n",
       "      <td>https://insights.blackcoffer.com/internet-dema...</td>\n",
       "      <td>27</td>\n",
       "      <td>12</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>blackassign0004</td>\n",
       "      <td>https://insights.blackcoffer.com/rise-of-cyber...</td>\n",
       "      <td>26</td>\n",
       "      <td>52</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>blackassign0005</td>\n",
       "      <td>https://insights.blackcoffer.com/ott-platform-...</td>\n",
       "      <td>18</td>\n",
       "      <td>7</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>93</th>\n",
       "      <td>blackassign0096</td>\n",
       "      <td>https://insights.blackcoffer.com/what-is-the-r...</td>\n",
       "      <td>21</td>\n",
       "      <td>34</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>94</th>\n",
       "      <td>blackassign0097</td>\n",
       "      <td>https://insights.blackcoffer.com/impact-of-cov...</td>\n",
       "      <td>16</td>\n",
       "      <td>25</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>95</th>\n",
       "      <td>blackassign0098</td>\n",
       "      <td>https://insights.blackcoffer.com/contribution-...</td>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>96</th>\n",
       "      <td>blackassign0099</td>\n",
       "      <td>https://insights.blackcoffer.com/how-covid-19-...</td>\n",
       "      <td>10</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>97</th>\n",
       "      <td>blackassign0100</td>\n",
       "      <td>https://insights.blackcoffer.com/how-will-covi...</td>\n",
       "      <td>21</td>\n",
       "      <td>35</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>98 rows × 4 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "             URL_ID                                                URL  \\\n",
       "0   blackassign0001  https://insights.blackcoffer.com/rising-it-cit...   \n",
       "1   blackassign0002  https://insights.blackcoffer.com/rising-it-cit...   \n",
       "2   blackassign0003  https://insights.blackcoffer.com/internet-dema...   \n",
       "3   blackassign0004  https://insights.blackcoffer.com/rise-of-cyber...   \n",
       "4   blackassign0005  https://insights.blackcoffer.com/ott-platform-...   \n",
       "..              ...                                                ...   \n",
       "93  blackassign0096  https://insights.blackcoffer.com/what-is-the-r...   \n",
       "94  blackassign0097  https://insights.blackcoffer.com/impact-of-cov...   \n",
       "95  blackassign0098  https://insights.blackcoffer.com/contribution-...   \n",
       "96  blackassign0099  https://insights.blackcoffer.com/how-covid-19-...   \n",
       "97  blackassign0100  https://insights.blackcoffer.com/how-will-covi...   \n",
       "\n",
       "    Positive Score  Negative Score  \n",
       "0                6               1  \n",
       "1               36              18  \n",
       "2               27              12  \n",
       "3               26              52  \n",
       "4               18               7  \n",
       "..             ...             ...  \n",
       "93              21              34  \n",
       "94              16              25  \n",
       "95               2               0  \n",
       "96              10               2  \n",
       "97              21              35  \n",
       "\n",
       "[98 rows x 4 columns]"
      ]
     },
     "execution_count": 37,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Total words after cleaning added to C:/Users/rohit/scraping/links.csv\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "import pandas as pd\n",
    "\n",
    "# Take user input for file paths\n",
    "modified_folder = \"C:/Users/rohit/scraping/txt_files_modified\"  # Change this to the path of your modified folder\n",
    "links_csv_path = \"C:/Users/rohit/scraping/links.csv\"  # Change this to the path of your links CSV file\n",
    "\n",
    "# Load the existing links CSV file\n",
    "links_df = pd.read_csv(links_csv_path)\n",
    "\n",
    "# Create an empty list to store total words after cleaning\n",
    "total_words_after_cleaning_list = []\n",
    "\n",
    "# Calculate total words after cleaning for each file and update the DataFrame\n",
    "for index, row in links_df.iterrows():\n",
    "    file_name = str(row[\"URL_ID\"]) if not pd.isna(row[\"URL_ID\"]) else \"\"\n",
    "  # Convert to string and handle NaN\n",
    "    \n",
    "    if file_name:  # Check if file_name is not empty\n",
    "        file_path = os.path.join(modified_folder, file_name + \".txt\")\n",
    "\n",
    "\n",
    "        with open(file_path, 'r', encoding='utf-8') as file:\n",
    "            content = file.read()\n",
    "\n",
    "        total_words_after_cleaning = len(content.split())  # Get total words after cleaning\n",
    "\n",
    "        total_words_after_cleaning_list.append(total_words_after_cleaning)\n",
    "    else:\n",
    "        # Handle the case where file_name is empty\n",
    "        print(f\"Skipping empty file name for row {index}\")\n",
    "\n",
    "# Add the list as a new column to the DataFrame\n",
    "links_df[\"Total Words After Cleaning\"] = total_words_after_cleaning_list\n",
    "\n",
    "# Save the updated DataFrame to the links CSV file\n",
    "links_df.to_csv(links_csv_path, index=False)\n",
    "\n",
    "print(f\"Total words after cleaning added to {links_csv_path}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Subjectivity Scores added to C:/Users/rohit/scraping/links.csv\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "import pandas as pd\n",
    "\n",
    "def calculate_subjectivity_score(positive_score, negative_score, total_words_after_cleaning):\n",
    "    subjectivity_score = (positive_score + negative_score) / (total_words_after_cleaning + 0.000001)\n",
    "    return subjectivity_score\n",
    "\n",
    "# Assuming you have a DataFrame named 'links_df' with columns 'Positive Score', 'Negative Score', and 'Total Words after cleaning'\n",
    "# You can replace these column names with the actual column names from your DataFrame\n",
    "\n",
    "links_df[\"Subjectivity Score\"] = links_df.apply(lambda row: calculate_subjectivity_score(row[\"Positive Score\"], row[\"Negative Score\"], row[\"Total Words After Cleaning\"]), axis=1)\n",
    "\n",
    "\n",
    "\n",
    "# Save the updated DataFrame to the links CSV file\n",
    "links_csv_path = \"C:/Users/rohit/scraping/links.csv\"  # Change this to the path of your links CSV file\n",
    "links_df.to_csv(links_csv_path, index=False)\n",
    "\n",
    "print(f\"Subjectivity Scores added to {links_csv_path}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "metadata": {},
   "outputs": [],
   "source": [
    "df['Polarity Score']=0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "metadata": {},
   "outputs": [],
   "source": [
    "df['Polarity Score']=(df['Positive Score']-df['Negative Score'])/(df['Positive Score']+df['Negative Score']+0.000001)\n",
    "links_df.to_csv(links_csv_path, index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>URL_ID</th>\n",
       "      <th>URL</th>\n",
       "      <th>Positive Score</th>\n",
       "      <th>Negative Score</th>\n",
       "      <th>Polarity Score</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>blackassign0001</td>\n",
       "      <td>https://insights.blackcoffer.com/rising-it-cit...</td>\n",
       "      <td>6</td>\n",
       "      <td>1</td>\n",
       "      <td>0.714286</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>blackassign0002</td>\n",
       "      <td>https://insights.blackcoffer.com/rising-it-cit...</td>\n",
       "      <td>36</td>\n",
       "      <td>18</td>\n",
       "      <td>0.333333</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>blackassign0003</td>\n",
       "      <td>https://insights.blackcoffer.com/internet-dema...</td>\n",
       "      <td>27</td>\n",
       "      <td>12</td>\n",
       "      <td>0.384615</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>blackassign0004</td>\n",
       "      <td>https://insights.blackcoffer.com/rise-of-cyber...</td>\n",
       "      <td>26</td>\n",
       "      <td>52</td>\n",
       "      <td>-0.333333</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>blackassign0005</td>\n",
       "      <td>https://insights.blackcoffer.com/ott-platform-...</td>\n",
       "      <td>18</td>\n",
       "      <td>7</td>\n",
       "      <td>0.440000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>93</th>\n",
       "      <td>blackassign0096</td>\n",
       "      <td>https://insights.blackcoffer.com/what-is-the-r...</td>\n",
       "      <td>21</td>\n",
       "      <td>34</td>\n",
       "      <td>-0.236364</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>94</th>\n",
       "      <td>blackassign0097</td>\n",
       "      <td>https://insights.blackcoffer.com/impact-of-cov...</td>\n",
       "      <td>16</td>\n",
       "      <td>25</td>\n",
       "      <td>-0.219512</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>95</th>\n",
       "      <td>blackassign0098</td>\n",
       "      <td>https://insights.blackcoffer.com/contribution-...</td>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "      <td>1.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>96</th>\n",
       "      <td>blackassign0099</td>\n",
       "      <td>https://insights.blackcoffer.com/how-covid-19-...</td>\n",
       "      <td>10</td>\n",
       "      <td>2</td>\n",
       "      <td>0.666667</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>97</th>\n",
       "      <td>blackassign0100</td>\n",
       "      <td>https://insights.blackcoffer.com/how-will-covi...</td>\n",
       "      <td>21</td>\n",
       "      <td>35</td>\n",
       "      <td>-0.250000</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>98 rows × 5 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "             URL_ID                                                URL  \\\n",
       "0   blackassign0001  https://insights.blackcoffer.com/rising-it-cit...   \n",
       "1   blackassign0002  https://insights.blackcoffer.com/rising-it-cit...   \n",
       "2   blackassign0003  https://insights.blackcoffer.com/internet-dema...   \n",
       "3   blackassign0004  https://insights.blackcoffer.com/rise-of-cyber...   \n",
       "4   blackassign0005  https://insights.blackcoffer.com/ott-platform-...   \n",
       "..              ...                                                ...   \n",
       "93  blackassign0096  https://insights.blackcoffer.com/what-is-the-r...   \n",
       "94  blackassign0097  https://insights.blackcoffer.com/impact-of-cov...   \n",
       "95  blackassign0098  https://insights.blackcoffer.com/contribution-...   \n",
       "96  blackassign0099  https://insights.blackcoffer.com/how-covid-19-...   \n",
       "97  blackassign0100  https://insights.blackcoffer.com/how-will-covi...   \n",
       "\n",
       "    Positive Score  Negative Score  Polarity Score  \n",
       "0                6               1        0.714286  \n",
       "1               36              18        0.333333  \n",
       "2               27              12        0.384615  \n",
       "3               26              52       -0.333333  \n",
       "4               18               7        0.440000  \n",
       "..             ...             ...             ...  \n",
       "93              21              34       -0.236364  \n",
       "94              16              25       -0.219512  \n",
       "95               2               0        1.000000  \n",
       "96              10               2        0.666667  \n",
       "97              21              35       -0.250000  \n",
       "\n",
       "[98 rows x 5 columns]"
      ]
     },
     "execution_count": 62,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "metadata": {},
   "outputs": [],
   "source": [
    "df=df.drop(['POLARITY SCORE'],axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>URL_ID</th>\n",
       "      <th>URL</th>\n",
       "      <th>Positive Score</th>\n",
       "      <th>Negative Score</th>\n",
       "      <th>Polarity Score</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>blackassign0001</td>\n",
       "      <td>https://insights.blackcoffer.com/rising-it-cit...</td>\n",
       "      <td>6</td>\n",
       "      <td>1</td>\n",
       "      <td>0.714286</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>blackassign0002</td>\n",
       "      <td>https://insights.blackcoffer.com/rising-it-cit...</td>\n",
       "      <td>36</td>\n",
       "      <td>18</td>\n",
       "      <td>0.333333</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>blackassign0003</td>\n",
       "      <td>https://insights.blackcoffer.com/internet-dema...</td>\n",
       "      <td>27</td>\n",
       "      <td>12</td>\n",
       "      <td>0.384615</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>blackassign0004</td>\n",
       "      <td>https://insights.blackcoffer.com/rise-of-cyber...</td>\n",
       "      <td>26</td>\n",
       "      <td>52</td>\n",
       "      <td>-0.333333</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>blackassign0005</td>\n",
       "      <td>https://insights.blackcoffer.com/ott-platform-...</td>\n",
       "      <td>18</td>\n",
       "      <td>7</td>\n",
       "      <td>0.440000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>93</th>\n",
       "      <td>blackassign0096</td>\n",
       "      <td>https://insights.blackcoffer.com/what-is-the-r...</td>\n",
       "      <td>21</td>\n",
       "      <td>34</td>\n",
       "      <td>-0.236364</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>94</th>\n",
       "      <td>blackassign0097</td>\n",
       "      <td>https://insights.blackcoffer.com/impact-of-cov...</td>\n",
       "      <td>16</td>\n",
       "      <td>25</td>\n",
       "      <td>-0.219512</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>95</th>\n",
       "      <td>blackassign0098</td>\n",
       "      <td>https://insights.blackcoffer.com/contribution-...</td>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "      <td>1.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>96</th>\n",
       "      <td>blackassign0099</td>\n",
       "      <td>https://insights.blackcoffer.com/how-covid-19-...</td>\n",
       "      <td>10</td>\n",
       "      <td>2</td>\n",
       "      <td>0.666667</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>97</th>\n",
       "      <td>blackassign0100</td>\n",
       "      <td>https://insights.blackcoffer.com/how-will-covi...</td>\n",
       "      <td>21</td>\n",
       "      <td>35</td>\n",
       "      <td>-0.250000</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>98 rows × 5 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "             URL_ID                                                URL  \\\n",
       "0   blackassign0001  https://insights.blackcoffer.com/rising-it-cit...   \n",
       "1   blackassign0002  https://insights.blackcoffer.com/rising-it-cit...   \n",
       "2   blackassign0003  https://insights.blackcoffer.com/internet-dema...   \n",
       "3   blackassign0004  https://insights.blackcoffer.com/rise-of-cyber...   \n",
       "4   blackassign0005  https://insights.blackcoffer.com/ott-platform-...   \n",
       "..              ...                                                ...   \n",
       "93  blackassign0096  https://insights.blackcoffer.com/what-is-the-r...   \n",
       "94  blackassign0097  https://insights.blackcoffer.com/impact-of-cov...   \n",
       "95  blackassign0098  https://insights.blackcoffer.com/contribution-...   \n",
       "96  blackassign0099  https://insights.blackcoffer.com/how-covid-19-...   \n",
       "97  blackassign0100  https://insights.blackcoffer.com/how-will-covi...   \n",
       "\n",
       "    Positive Score  Negative Score  Polarity Score  \n",
       "0                6               1        0.714286  \n",
       "1               36              18        0.333333  \n",
       "2               27              12        0.384615  \n",
       "3               26              52       -0.333333  \n",
       "4               18               7        0.440000  \n",
       "..             ...             ...             ...  \n",
       "93              21              34       -0.236364  \n",
       "94              16              25       -0.219512  \n",
       "95               2               0        1.000000  \n",
       "96              10               2        0.666667  \n",
       "97              21              35       -0.250000  \n",
       "\n",
       "[98 rows x 5 columns]"
      ]
     },
     "execution_count": 56,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>URL_ID</th>\n",
       "      <th>URL</th>\n",
       "      <th>Positive Score</th>\n",
       "      <th>Negative Score</th>\n",
       "      <th>Polarity Score</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>blackassign0001</td>\n",
       "      <td>https://insights.blackcoffer.com/rising-it-cit...</td>\n",
       "      <td>6</td>\n",
       "      <td>1</td>\n",
       "      <td>0.714286</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>blackassign0002</td>\n",
       "      <td>https://insights.blackcoffer.com/rising-it-cit...</td>\n",
       "      <td>36</td>\n",
       "      <td>18</td>\n",
       "      <td>0.333333</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>blackassign0003</td>\n",
       "      <td>https://insights.blackcoffer.com/internet-dema...</td>\n",
       "      <td>27</td>\n",
       "      <td>12</td>\n",
       "      <td>0.384615</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>blackassign0004</td>\n",
       "      <td>https://insights.blackcoffer.com/rise-of-cyber...</td>\n",
       "      <td>26</td>\n",
       "      <td>52</td>\n",
       "      <td>-0.333333</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>blackassign0005</td>\n",
       "      <td>https://insights.blackcoffer.com/ott-platform-...</td>\n",
       "      <td>18</td>\n",
       "      <td>7</td>\n",
       "      <td>0.440000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>93</th>\n",
       "      <td>blackassign0096</td>\n",
       "      <td>https://insights.blackcoffer.com/what-is-the-r...</td>\n",
       "      <td>21</td>\n",
       "      <td>34</td>\n",
       "      <td>-0.236364</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>94</th>\n",
       "      <td>blackassign0097</td>\n",
       "      <td>https://insights.blackcoffer.com/impact-of-cov...</td>\n",
       "      <td>16</td>\n",
       "      <td>25</td>\n",
       "      <td>-0.219512</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>95</th>\n",
       "      <td>blackassign0098</td>\n",
       "      <td>https://insights.blackcoffer.com/contribution-...</td>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "      <td>1.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>96</th>\n",
       "      <td>blackassign0099</td>\n",
       "      <td>https://insights.blackcoffer.com/how-covid-19-...</td>\n",
       "      <td>10</td>\n",
       "      <td>2</td>\n",
       "      <td>0.666667</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>97</th>\n",
       "      <td>blackassign0100</td>\n",
       "      <td>https://insights.blackcoffer.com/how-will-covi...</td>\n",
       "      <td>21</td>\n",
       "      <td>35</td>\n",
       "      <td>-0.250000</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>98 rows × 5 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "             URL_ID                                                URL  \\\n",
       "0   blackassign0001  https://insights.blackcoffer.com/rising-it-cit...   \n",
       "1   blackassign0002  https://insights.blackcoffer.com/rising-it-cit...   \n",
       "2   blackassign0003  https://insights.blackcoffer.com/internet-dema...   \n",
       "3   blackassign0004  https://insights.blackcoffer.com/rise-of-cyber...   \n",
       "4   blackassign0005  https://insights.blackcoffer.com/ott-platform-...   \n",
       "..              ...                                                ...   \n",
       "93  blackassign0096  https://insights.blackcoffer.com/what-is-the-r...   \n",
       "94  blackassign0097  https://insights.blackcoffer.com/impact-of-cov...   \n",
       "95  blackassign0098  https://insights.blackcoffer.com/contribution-...   \n",
       "96  blackassign0099  https://insights.blackcoffer.com/how-covid-19-...   \n",
       "97  blackassign0100  https://insights.blackcoffer.com/how-will-covi...   \n",
       "\n",
       "    Positive Score  Negative Score  Polarity Score  \n",
       "0                6               1        0.714286  \n",
       "1               36              18        0.333333  \n",
       "2               27              12        0.384615  \n",
       "3               26              52       -0.333333  \n",
       "4               18               7        0.440000  \n",
       "..             ...             ...             ...  \n",
       "93              21              34       -0.236364  \n",
       "94              16              25       -0.219512  \n",
       "95               2               0        1.000000  \n",
       "96              10               2        0.666667  \n",
       "97              21              35       -0.250000  \n",
       "\n",
       "[98 rows x 5 columns]"
      ]
     },
     "execution_count": 58,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "metadata": {},
   "outputs": [],
   "source": [
    "links_df.to_csv(\"C:/Users/rohit/scraping/links.csv\", index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "soup",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
